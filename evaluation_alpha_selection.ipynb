{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.patches as mpatches\n",
    "from lifelines.utils import concordance_index\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "from scipy.special import gamma, erf\n",
    "import math\n",
    "\n",
    "fontsize = 14\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "legend_size =14\n",
    "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 24}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          # 'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "sns.set()\n",
    "np.random.seed(31415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best perfoming alpha according to validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis/actg175_simulated/alpha_100/CSA-INFO/\n",
      "pred_t0_f:  (96, 200)\n",
      "pred_t0_cf:  (118, 200)\n",
      "pred_t1_f:  (118, 200)\n",
      "pred_t1_cf:  (96, 200)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "alpha = \"100\" # alpha=[0, 0.1, 1, 10, 100]\n",
    "\n",
    "model = 'CSA-INFO'\n",
    "is_non_param = True\n",
    "is_stochastic = True\n",
    "\n",
    "if 'SR' in model:\n",
    "    is_stochastic = False\n",
    "    \n",
    "if 'AFT' in model:\n",
    "    is_non_param = False      \n",
    "    \n",
    "#data = 'actg175'\n",
    "data = 'actg175_simulated'\n",
    "\n",
    "if alpha:\n",
    "    main_path = 'analysis/{}/alpha_{}/'.format(data, alpha)\n",
    "    path = 'analysis/{}/alpha_{}/{}/'.format(data, alpha, model)\n",
    "else:\n",
    "    path = 'analysis/{}/{}/'.format(data +'_{}_split'.format(split), model)\n",
    "    main_path = 'analysis/{}/'.format(data +'_{}_split'.format(split))\n",
    "\n",
    "\n",
    "#data = 'sythentic'\n",
    "#path = 'analysis/{}/alpha_{}/{}/'.format(fld,alpha,  model)\n",
    "\n",
    "print(path)\n",
    "has_cf = True\n",
    "time = 'days'\n",
    "name = 'Valid'\n",
    "if is_non_param:\n",
    "    pred_t0_f = np.load(path + '{}_pred_t0_F.npy'.format(name))\n",
    "    pred_t0_cf = np.load(path +  '{}_pred_t0_CF.npy'.format(name))\n",
    "\n",
    "    pred_t1_f = np.load(path +  '{}_pred_t1_F.npy'.format(name))\n",
    "    pred_t1_cf = np.load(path +  '{}_pred_t1_CF.npy'.format(name))\n",
    "    print(\"pred_t0_f: \", pred_t0_f.shape)\n",
    "    print(\"pred_t0_cf: \", pred_t0_cf.shape)\n",
    "\n",
    "    print(\"pred_t1_f: \", pred_t1_f.shape)\n",
    "    print(\"pred_t1_cf: \", pred_t1_cf.shape)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    pred_t0_f = pandas.read_csv(path + '{}_pred_t0_F.csv'.format(name))\n",
    "    pred_t0_cf = pandas.read_csv(path +  '{}_pred_t0_CF.csv'.format(name))\n",
    "\n",
    "    pred_t1_f = pandas.read_csv(path +  '{}_pred_t1_F.csv'.format(name))\n",
    "    pred_t1_cf = pandas.read_csv(path +  '{}_pred_t1_CF.csv'.format(name))\n",
    "    \n",
    "    print(\"pred_t0_f: \", pred_t0_f.shape,pred_t0_f.head())\n",
    "    print(\"pred_t0_cf: \", pred_t0_cf.shape, pred_t0_cf.head())\n",
    "\n",
    "    print(\"pred_t1_f: \", pred_t1_f.shape, pred_t1_f.head())\n",
    "    print(\"pred_t1_cf: \", pred_t1_cf.shape, pred_t1_cf.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_factual:  data/actg175_simulated/actg175_simulated_valid_idx.csv\n",
      "a:  (214,)\n",
      "y_cf:  (214,)\n",
      "e_cf:  (214,)\n",
      "y_f:  (214,)\n",
      "e_f:  (214,)\n",
      "a=1 118.0\n",
      "y_f[a==1.0].shape (118,)\n",
      "y_f[a==0.0].shape (96,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_factual = 'data/{}/{}_{}_idx.csv'.format(data, data, name.lower())\n",
    "print(\"path_factual: \", path_factual)\n",
    "data_frame = pandas.read_csv(path_factual)\n",
    "## Factual\n",
    "y_f = data_frame[['time']]\n",
    "e_f = data_frame[['event']]\n",
    "a = data_frame[['treatment']]\n",
    "    \n",
    "y_f = np.array(y_f).reshape(len(y_f))\n",
    "e_f = np.array(e_f).reshape(len(e_f))\n",
    "a = np.array(a).reshape(len(a))\n",
    "    \n",
    "## Counter Factual\n",
    "y_cf = data_frame[['nn_cf_y']]\n",
    "e_cf = data_frame[['nn_cf_e']]\n",
    "y_cf = np.array(y_cf).reshape(len(y_cf))\n",
    "e_cf = np.array(e_cf).reshape(len(e_cf))\n",
    "    \n",
    "print(\"a: \", a.shape)\n",
    "print(\"y_cf: \", y_cf.shape)\n",
    "print(\"e_cf: \", e_cf.shape)\n",
    "print(\"y_f: \", y_f.shape)\n",
    "print(\"e_f: \", e_f.shape)\n",
    "print(\"a=1\", np.sum(a))\n",
    "print(\"y_f[a==1.0].shape\", y_f[a==1].shape)\n",
    "print(\"y_f[a==0.0].shape\", y_f[a==0].shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Factual + Counterfactual Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_lik:  126.37\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def weibull_lik(pred_t, y, e, name):\n",
    "    shape =  pred_t['logshape_' + name]\n",
    "    scale = pred_t['logscale_' + name]\n",
    "    \n",
    "    log_k = shape\n",
    "    log_lam = scale\n",
    "    \n",
    "    k = np.exp(log_k)\n",
    "    lam = np.exp(log_lam)\n",
    "    \n",
    "    log_surv = - (y / lam) ** k\n",
    "    log_weibull = log_k - log_lam + (k - 1) * (np.log(y) - log_lam) - (y / lam) ** k\n",
    "    \n",
    "    return -log_weibull * e + -log_surv * (1-e) \n",
    "\n",
    "def lognormal_lik(pred_t, y, e, name):\n",
    "    mu = pred_t['mu_' + name]\n",
    "    logvar = pred_t['logvar_' + name]\n",
    "    stddev = np.exp(logvar * 0.5)\n",
    "    \n",
    "    constant = 1e-8\n",
    "    log_t = np.log(y + constant)\n",
    "    \n",
    "    log_pdf = -0.5 * (logvar + np.power(log_t - mu, 2) / np.exp(logvar))\n",
    "    \n",
    "    norm_diff = (log_t - mu) / stddev\n",
    "    sqrt_2 = math.sqrt(2)\n",
    "    cdf = 0.5 * (1.0 + erf(norm_diff / sqrt_2))\n",
    "    log_surv = np.log(1 - cdf + constant)\n",
    "    \n",
    "    return -log_pdf * e + -log_surv * (1-e)\n",
    "    \n",
    "\n",
    "def non_param_lik(pred_t_samples, y, e):\n",
    "    pred_t = np.mean(pred_t_samples,  axis=1)\n",
    "    return np.abs(y - pred_t) * e + relu(y - pred_t)*(1-e)\n",
    "    \n",
    "\n",
    "if is_non_param:\n",
    "    \n",
    "    pred_lik_t1_f = non_param_lik(pred_t1_f, y=y_f[a==1], e=e_f[a==1]) \n",
    "    pred_lik_t0_cf = non_param_lik(pred_t0_cf, y=y_cf[a==1], e=e_cf[a==1])\n",
    "   \n",
    "    pred_lik_t1_cf = non_param_lik(pred_t1_cf, y=y_cf[a==0], e=e_cf[a==0]) \n",
    "    pred_lik_t0_f = non_param_lik(pred_t0_f, y=y_f[a==0], e=e_f[a==0])\n",
    "   \n",
    "    \n",
    "  \n",
    "elif 'Weibull'  not in model:\n",
    "    pred_lik_t1_f = lognormal_lik(pred_t1_f, y=y_f[a==1], e=e_f[a==1], name='one') \n",
    "    pred_lik_t0_cf = lognormal_lik(pred_t0_cf,y=y_cf[a==1], e=e_cf[a==1], name='zero')\n",
    "    \n",
    "    pred_lik_t1_cf = lognormal_lik(pred_t1_cf, y=y_cf[a==0], e=e_cf[a==0],  name='one') \n",
    "    pred_lik_t0_f = lognormal_lik(pred_t0_f, y=y_f[a==0], e=e_f[a==0], name='zero')\n",
    "    \n",
    "  \n",
    "\n",
    "else:\n",
    "    pred_lik_t1_f = weibull_lik(pred_t1_f, y=y_f[a==1], e=e_f[a==1], name='one') \n",
    "    pred_lik_t0_cf = weibull_lik(pred_t0_cf,y=y_cf[a==1], e=e_cf[a==1], name='zero')\n",
    "    \n",
    "    pred_lik_t1_cf = weibull_lik(pred_t1_cf, y=y_cf[a==0], e=e_cf[a==0],  name='one') \n",
    "    pred_lik_t0_f = weibull_lik(pred_t0_f, y=y_f[a==0], e=e_f[a==0], name='zero')\n",
    "    \n",
    "\n",
    "pred_lik = (np.mean(pred_lik_t1_f) + np.mean(pred_lik_t0_cf)+ np.mean(pred_lik_t1_cf) \n",
    "            + np.mean(pred_lik_t0_f)) * 0.25 \n",
    "print(\"pred_lik: \", np.round(pred_lik, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
